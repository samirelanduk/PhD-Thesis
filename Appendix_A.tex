%%%% MACRO DEFINITION %%%%
% if any ...


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%													BEGIN
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{atomium} % Write in your own chapter title
\lhead{Appendix. \emph{A}} % Write in your own chapter title to set the page header

%TC:macro \note [ignore]

% write your code here
Much of this project relies very heavily on reading in structure data from files deposited to the Protein Data Bank.

Traditionally these files have been stored and distributed in the form of .pdb files. These are text files that consist of a list of records, with each record being limited to 80 characters. Information is stored in these records at fixed offsets from the start of the line. This file format has a number of limitations - most notably the fact that they cannot store more than 100,000 atoms because only five characters are allocated to atom IDs, and so they cannot go past 99,999.

Consequently, the Protein Data Bank also provides files in the newer .cif file format - and indeed, structures with more than 100,000 atoms are \emph{only} available in this file format.

There are a number of parsers available that can handle these file formats, and which were considered for use in this project - both in Python and otherwise. However, for reasons that will be outlined shortly, it was decided to create a novel Python parser. This parser is called atomium.

\section{Rationale}

The tool used to read structure files is of such critical importance to this project, that it was important to ensure that the correct tool with the correct \emph{capabilities} was used. Specifically, the tool would need the following properties:

\begin{itemize}
  \item The ability to read .pdb files.
  \item The ability to read .cif files.
\end{itemize}

Probably the major Python PDB parser at time of writing is BioPython. This is a multi-purpose bioinformatics library, with many modules for dealing with general biological data formats. One of these modules allows for parsing of PDB structure files.

\section{Data Structures}

The object returned by the various parsing functions is a \texttt{File} object. This essentially represents the actual file object itself rather than its structural contents, and has attributes for PDB code, resolution, keywords, etc.

A \texttt{File} object has one or more \texttt{Model} objects.

\section{Parsing}

atomium can read .cif, .mmtf, or .pdb files. In each case the overall process is the same.

\begin{enumerate}
   \item Get the file contents as a string.
   \item Determine which filetype it is by looking at file extension or, if not possible, by looking at file contents.
   \item Convert the filestring to a Python dictionary whose structure is specific to that file type.
   \item Convert that dictionary to a standard atomium data dictionary, whose structure is the same regardless of the file type origin.
   \item Convert that data dictionary to an atomium \texttt{File} object with one or more \texttt{File}s within it.
\end{enumerate}

This process for parsing has a number of advantages over just trying to go from filestring to parsed object in one step. By making the three filetypes converge at one data structure - the atomium data dictionary - it prevents duplication of effort involved in going from `data' to `Python structure'. It also means that every file can have a consistent, dictionary representations, which means that they can all be represented as JSON if desired. It is also easier for testing, as each stage in this (relatively complex) parsing process can more easily be tested in isolation.

\subsection{File Contents and File Type Detection}

Getting the file contents as a string is a straightforward process - it is simply opened and read using the built in Python functions for that. The process is abstracted into a single function which will first try to read the file as a unicode string (appropriate for .cif and .pdb) and then as binary data (appropriate for .mmtf).

atomium also enables `fetching' a file from a remote server. Generally this is via HTTP, from the RCSB web servers \note{Cite this!} with a four letter code, though the user can select any URL. The Python library requests \note{Cite somehow} is used for this. Alternatively the user can fetch a file over SSH using a different function.

Once the file contents are extracted as a string (or bytestring), atomium then determines which of the three file types it has been given, so it knows which functions to use to process it further. This is done using a straightforward algorithm - if the file extension is given, this will be used to determine filetype. If not, or if the filetype is not one of the three it recognises (such as .ent for example), atomium will assume it is .mmtf if the data is binary, .cif if it is a unicode string that contains the string \texttt{\_atom\_sites}, and .pdb otherwise.

\subsection{File Dictionaries}

The next step is to convert this string into a Python dictionary that reflects the internal structure of that file type.

.cif files are essentially a list of connected tables - tables in the sense that each block has a list of headers, and then one or more lists of values that belong to those headers, and connected in the sense that a row may have an ID as its first value which is refered to in another table. atomium represents these tables as lists of dictionaires, where the headers are keys, and the row cells the values. Each of these table lists is a value in the top-level dictionary. \note{This definitely needs a figure or something to show what I'm talking about.} The main bottleneck in this process is splitting values on a single line - they are white-space separated, albeit with whitepsace within quotes ignored, and with both quote types permissable and escapable within the other. Initially the Python library shlex was used to do this splitting, but its speed was just too slow so a custom function was written which was faster - though still the slowest part of the process.

.mmtf are binary encoded msgpack \note{cite} dictionaries, so once the Python msgpack library has decoded it, it is essentially already in dictionary form. The only extra steps that need to be taken are to decode the .mmtf formatted binary fields within this dictionary, using the algorithms specified in the .mmtf documentation and implemented in atomium.

.pdb files have much less internal structure than the other two, and are essentially just lists of records. These records can be grouped by record name however, and this is what atomium does - the file dictionary has record names as keys, and lists of records that belong to that record type as values. The only exceptions are \texttt{REMARK} records, which are further grouped by remark number, and all model related records (\texttt{ATOM}, \texttt{TER}, \texttt{HETATM} etc.), which are grouped together because their order relative to each other is information that would be lost of they were split up into record types (\texttt{TER} records separating chains being the main reason).

This resultant file dictionary, whose internal structure is specific to file type, is essentially just a Python representation of the file contents - no `parsing' is done as such, it just gets the information in a form that later processes can understand. 

\section{Saving}

One of the more unique features of atomium is that it allows changes to models to be made and then for those changes to be saved in \emph{any} of the three file types that atomium supports.

Unlike the process of parsing, in which the structures pass through a number of different representations reflecting the different layers of abstraction of that process, saving is much more starightforward. A function takes in an atomium \texttt{AtomStructure} (it doesn't need to be a model, chains etc. can be saved individually) and turns it into the relevant filestring.

Only structural information is saved - the various file annotations that are parsed from the original files are presumed to be properties solely of those original files, and not of any modified versions of them that might exist. So, atom records are saved, along with anything else needed to construct details of the actual structure model - but not titles, deposition dates, resolution etc.

\section{Usage}

%%%%%%%%%%%% END %%%%%%%%%%%%
